import os
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from pinecone import Pinecone
import openai
import pandas as pd

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv()
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# 2. ëª¨ë¸ ì´ˆê¸°í™”
model = SentenceTransformer("jhgan/ko-sbert-nli")
pc = Pinecone(api_key=PINECONE_API_KEY)
client = openai.OpenAI(api_key=OPENAI_API_KEY)

# 3. ì‚¬ìš©ì ì…ë ¥ ì˜ˆì‹œ
user_input = {
    "skin_type": "ì§€ì„±",
    "sensitivity": "ë†’ìŒ",
    "diagnosis": ["ì—¬ë“œë¦„", "ì—¼ì¦ì„±"]
}
query = " ".join(user_input["diagnosis"])
query_embedding = model.encode([query])[0].tolist()

INDEXES = {
    "í† ë„ˆ": "toner",
    "ì•°í”Œ": "ampoule",
    "í¬ë¦¼": "cream"
}

final_recommend_list = []

for category, index_name in INDEXES.items():
    index = pc.Index(index_name)
    result = index.query(vector=query_embedding, top_k=20, include_metadata=True)
    matches = result.get("matches", [])
    if not matches:
        continue
    best = max(matches, key=lambda x: x["score"])
    meta = best["metadata"]
    final_recommend_list.append({
        "ì¹´í…Œê³ ë¦¬": category,
        "ì œí’ˆëª…": meta.get("product_name", ""),
        "í”¼ë¶€íƒ€ì…": meta.get("skin_type", "")
    })

# ì—°ê³ ë„ ê°™ì´ ê²€ìƒ‰
ointment_index = pc.Index("ointment")
result = ointment_index.query(vector=query_embedding, top_k=5, include_metadata=True)
matches = result.get("matches", [])
best_ointment = max(matches, key=lambda x: x["score"]) if matches else None
ointment_meta = best_ointment["metadata"] if best_ointment else {}

# 4. GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
prompt = f"""ë„ˆëŠ” í”¼ë¶€ê³¼ ì¶”ì²œ ì „ë¬¸ê°€ì•¼.

í”¼ë¶€ íƒ€ì…: {user_input['skin_type']}
ë¯¼ê°ë„: {user_input['sensitivity']}
í”¼ë¶€ ì§„ë‹¨ ê²°ê³¼: {', '.join(user_input['diagnosis'])}

ì•„ë˜ëŠ” ê° í™”ì¥í’ˆ ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì²œ í›„ë³´ì•¼:
"""

for r in final_recommend_list:
    prompt += f"- {r['ì¹´í…Œê³ ë¦¬']} | {r['ì œí’ˆëª…']}:\"\n"

if ointment_meta:
    prompt += f"""
ì¶”ê°€ ì—°ê³  í›„ë³´:
- ì—°ê³  | {ointment_meta.get('product_name', '')}: \"{ointment_meta.get('effect', '')}\"
"""

prompt += """
ì¶”ì²œ ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ì²˜ëŸ¼ ì •ë¦¬í•´ì¤˜:

1. í™”ì¥í’ˆ ì¶”ì²œ (í† ë„ˆ, ì•°í”Œ, í¬ë¦¼): ê° 1ê°œì”©, ì´ë¦„ê³¼ ì¶”ì²œ ì´ìœ  í•œ ì¤„ë¡œ
2. ì—°ê³  ì¶”ì²œ: ì œí’ˆëª… - ì´ìœ 
3. ì‹œìˆ  ì¶”ì²œ:
   - ì‹œìˆ 1 - ì´ìœ 
   - ì‹œìˆ 2 - ì´ìœ 

ë¶ˆí•„ìš”í•œ ë§íˆ¬, ì´ëª¨ì§€ ì—†ì´ ê¹”ë”í•˜ê³  ì •í™•í•˜ê²Œ. ê° ë¬¸ì¥ì€ 1ì¤„ ì´ë‚´ë¡œ.
"""

# 5. GPT í˜¸ì¶œ
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.4,
    max_tokens=400
)

# 6. ê²°ê³¼ ì¶œë ¥
print("\nğŸ¯ GPT ì¢…í•© ì¶”ì²œ ê²°ê³¼:\n")
print(response.choices[0].message.content.strip())
