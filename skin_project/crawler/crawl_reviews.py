from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import time

def setup_driver():
    options = webdriver.ChromeOptions()
    options.add_argument('--start-maximized')
    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

def crawl_product_and_reviews(url):
    driver = setup_driver()
    driver.get(url)
    wait = WebDriverWait(driver, 10)
    time.sleep(2)

    # ìƒí’ˆëª…
    try:
        product_name = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'p.prd_name'))).text.strip()
    except:
        product_name = 'ìƒí’ˆëª… ì—†ìŒ'

    # ê°€ê²©
    try:
        price_discounted = driver.find_element(By.CSS_SELECTOR, 'span.price-2 > strong').text.strip()
    except:
        price_discounted = 'ì—†ìŒ'

    try:
        price_original = driver.find_element(By.CSS_SELECTOR, 'span.price-1 > strike').text.strip()
    except:
        price_original = 'ì—†ìŒ'

    # ìƒí’ˆ ì„¤ëª…
    try:
        btn = driver.find_element(By.ID, 'btn_toggle_detail_image')
        driver.execute_script("arguments[0].click();", btn)
        time.sleep(1)
        description = 'ì´ë¯¸ì§€ë¡œ êµ¬ì„±ëœ ìƒí’ˆ ì„¤ëª…'
    except:
        description = 'ì„¤ëª… ì—†ìŒ'

    print(f"âœ… ìƒí’ˆëª…: {product_name}")
    print(f"ğŸ’° ì •ìƒê°€: {price_original}")
    print(f"ğŸ’° í• ì¸ê°€: {price_discounted}")
    print(f"ğŸ“ƒ ì„¤ëª…: {description}")

    # ë¦¬ë·° íƒ­ í´ë¦­
    try:
        review_tab = driver.find_element(By.CSS_SELECTOR, 'a.goods_reputation')
        review_tab.click()
        time.sleep(2)
    except Exception as e:
        print(f"âŒ ë¦¬ë·° íƒ­ í´ë¦­ ì‹¤íŒ¨: {e}")

    # í¬ë¡¤ë§
    usernames, reviews, dates, skintypes, concerns, sensitivities, ratings = [], [], [], [], [], [], []

    for page in range(1, 3):  # ì›í•˜ëŠ” ë§Œí¼ ì¡°ì ˆ
        print(f"ğŸ“„ {page}í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")
        time.sleep(2)

        review_items = driver.find_elements(By.CSS_SELECTOR, 'ul#gdasList > li')
        for item in review_items:
            try:
                username = item.find_element(By.CSS_SELECTOR, 'div.user.clrfix').text.strip()
            except:
                username = 'ì—†ìŒ'

            try:
                review_text = item.find_element(By.CSS_SELECTOR, 'div.txt_inner').text.strip()
            except:
                review_text = 'ì—†ìŒ'

            try:
                date = item.find_element(By.CSS_SELECTOR, 'span.date').text.strip()
            except:
                date = 'ì—†ìŒ'

            try:
                skin = item.find_element(By.XPATH, ".//dl[@class='poll_type1'][1]/dd").text.strip()
            except:
                skin = 'ì—†ìŒ'

            try:
                concern = item.find_element(By.XPATH, ".//dl[@class='poll_type1'][2]/dd").text.strip()
            except:
                concern = 'ì—†ìŒ'

            try:
                sensitivity = item.find_element(By.XPATH, ".//dl[@class='poll_type1'][3]/dd").text.strip()
            except:
                sensitivity = 'ì—†ìŒ'

            try:
                rating = item.find_element(By.CSS_SELECTOR, 'span.point').get_attribute("style")
                score = rating.split("width:")[1].replace("%", "").replace(";", "").strip()
                star = round(float(score) / 20, 1)  # 100% -> 5ì 
            except:
                star = 'ì—†ìŒ'

            usernames.append(username)
            reviews.append(review_text)
            dates.append(date)
            skintypes.append(skin)
            concerns.append(concern)
            sensitivities.append(sensitivity)
            ratings.append(star)

        # ë‹¤ìŒ í˜ì´ì§€ í´ë¦­
        try:
            next_btn = driver.find_element(By.LINK_TEXT, str(page + 1))
            driver.execute_script("arguments[0].click();", next_btn)
        except:
            print("âŒ ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ")
            break

    driver.quit()

    df = pd.DataFrame({
        'ìƒí’ˆëª…': product_name,
        'ì •ìƒê°€': price_original,
        'í• ì¸ê°€': price_discounted,
        'ì„¤ëª…': description,
        'ì‘ì„±ì': usernames,
        'ì‘ì„±ì¼ì': dates,
        'í”¼ë¶€íƒ€ì…': skintypes,
        'í”¼ë¶€ê³ ë¯¼': concerns,
        'ìê·¹ë„': sensitivities,
        'ë³„ì ': ratings,
        'ë¦¬ë·°ë‚´ìš©': reviews
    })

    # ì—‘ì…€ë¡œ ì €ì¥
    df.to_excel('oliveyoung_reviews_final.xlsx', index=False)
    print("âœ… ë¦¬ë·° ì €ì¥ ì™„ë£Œ: oliveyoung_reviews_final.xlsx")

# ì‹¤í–‰
product_url = "https://www.oliveyoung.co.kr/store/goods/getGoodsDetail.do?goodsNo=A000000202893&dispCatNo=90000010001&trackingCd=Home_Curation1_1&curation=like&egcode=a016_a016&rccode=pc_main_01_c&egrankcode=6&t_page=%ED%99%88&t_click=%ED%81%90%EB%A0%88%EC%9D%B4%EC%85%981_%EC%83%81%ED%92%88%EC%83%81%EC%84%B8&t_number=1"
crawl_product_and_reviews(product_url)
