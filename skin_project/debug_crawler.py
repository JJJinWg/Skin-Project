import time
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

def crawl_olive_young_reviews(max_products=10):
    """ì˜¬ë¦¬ë¸Œì˜ ìƒí’ˆ ë¦¬ë·°ë¥¼ í¬ë¡¤ë§í•´ì„œ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤ (ìµœì‹  ì…€ë ‰í„° + JS ë Œë”ë§ ëŒ€ê¸°)."""
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    driver = webdriver.Chrome(options=options)
    base_url = "https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010013"

    print("[1] ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ì ‘ì† ì¤‘...")
    driver.get(base_url)

    
    # âœ… ë Œë”ë§ ê¸°ë‹¤ë¦¬ê¸° (ì…€ë ‰í„°ê°€ ë³´ì¼ ë•Œê¹Œì§€)
    wait = WebDriverWait(driver, 10)
    items = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "a.name")))
    print(f"[DEBUG] ìƒí’ˆ ìš”ì†Œ ìˆ˜: {len(items)}")

    print("[1] ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ì ‘ì† ì¤‘...")
    driver.get(base_url)
    time.sleep(3)

    # ğŸ‘‡ ìŠ¤í¬ë¡¤ë¡œ ë¡œë”© ìœ ë„
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(3)

    wait = WebDriverWait(driver, 10)
    items = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "a.name")))


    print("[2] ìƒí’ˆ URL ìˆ˜ì§‘ ì¤‘...")
    product_links = []
    for item in items[:max_products]:
        url = item.get_attribute("href")
        if url:
            if not url.startswith("http"):
                url = "https://www.oliveyoung.co.kr" + url
            print(f"[DEBUG] ìƒí’ˆ URL: {url}")
            product_links.append(url)

    if not product_links:
        print("[ERROR] ìƒí’ˆ URLì„ í•˜ë‚˜ë„ ê°€ì ¸ì˜¤ì§€ ëª»í•¨.")
        driver.quit()
        return pd.DataFrame()

    all_reviews = []

    for link in product_links:
        try:
            print(f"[3] ë¦¬ë·° ìˆ˜ì§‘ ì¤‘: {link}")
            driver.get(link)
            time.sleep(3)
            soup = BeautifulSoup(driver.page_source, "html.parser")

            product_name_tag = soup.select_one("span.prd_name")
            product_name = product_name_tag.text.strip() if product_name_tag else "Unknown"

            review_elements = soup.select("div.review_cont")
            print(f"[DEBUG] ë¦¬ë·° ê°œìˆ˜: {len(review_elements)}")
            for review in review_elements:
                content = review.text.strip()
                all_reviews.append({"product": product_name, "review": content})

        except Exception as e:
            print(f"[ì˜¤ë¥˜] {link} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    driver.quit()
    print(f"[ì™„ë£Œ] ì´ ë¦¬ë·° ìˆ˜: {len(all_reviews)}")
    return pd.DataFrame(all_reviews)

if __name__ == "__main__":
    df = crawl_olive_young_reviews()
    print(df.head())
