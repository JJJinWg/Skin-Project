from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
# from pinecone import Pinecone  # ì„ì‹œ ë¹„í™œì„±í™”
from openai import OpenAI
from crawler.recommend_utils import generate_recommend_query
import os
from uuid import uuid4
from typing import List  # âœ… ì¶”ê°€

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
env_path = os.path.join(os.path.dirname(__file__), ".env")
load_dotenv(dotenv_path=env_path)

openai_api_key = os.getenv("OPENAI_API_KEY")
# pinecone_api_key = os.getenv("PINECONE_API_KEY")  # ì„ì‹œ ë¹„í™œì„±í™”
# pinecone_env = os.getenv("PINECONE_ENV")  # ì„ì‹œ ë¹„í™œì„±í™”
# pinecone_index_name = os.getenv("PINECONE_INDEX", "toner")  # ì„ì‹œ ë¹„í™œì„±í™”

print("âœ… OPENAI_API_KEY =", openai_api_key[:10] + "..." if openai_api_key else None)
# print("ğŸ” PINECONE_API_KEY =", pinecone_api_key[:10] + "..." if pinecone_api_key else None)
# print("ğŸ” PINECONE_ENV =", pinecone_env)
# print("ğŸ” PINECONE_INDEX =", pinecone_index_name)

# if not openai_api_key:
#     raise RuntimeError("âŒ OPENAI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
# if not pinecone_api_key or not pinecone_env:
#     raise RuntimeError("âŒ PINECONE_API_KEY ë˜ëŠ” PINECONE_ENVê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

# client = OpenAI(api_key=openai_api_key) if openai_api_key else None
# pc = Pinecone(api_key=pinecone_api_key, environment=pinecone_env)

# if pinecone_index_name not in pc.list_indexes().names():
#     raise RuntimeError(f"'{pinecone_index_name}' ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# index = pc.Index(pinecone_index_name)
model = SentenceTransformer("jhgan/ko-sbert-nli")
app = FastAPI()

# âœ… ìƒ˜í”Œ í† ë„ˆ ë°ì´í„° ì—…ë¡œë“œ
@app.on_event("startup")
async def upload_sample_data():
    try:
        reviews = [
            ("ê±´ì„±", "ë¼ìš´ë“œë© ìì‘ë‚˜ë¬´ í† ë„ˆ", "ì†ë³´ìŠµì´ ì˜ ë˜ê³  ê°ì§ˆ ë¶€ê°ì´ ëœí•´ìš”."),
            ("ì§€ì„±", "ì´ë‹ˆìŠ¤í”„ë¦¬ ë¸”ë£¨ë² ë¦¬ ë¦¬ë°¸ëŸ°ì‹± í† ë„ˆ", "ëˆì ì„ ì—†ì´ ì‚°ëœ»í•´ì„œ ì—¬ë¦„ì— ì¢‹ì•„ìš”."),
            ("ë¯¼ê°ì„±", "ì•„ë²¤ëŠ í† ë„ˆ", "ìê·¹ ì—†ì´ ì§„ì •ë¼ì„œ í”¼ë¶€ ì§„ì •ìš©ìœ¼ë¡œ ë”±ì´ì—ìš”."),
        ]
        for skin_type, product_name, review in reviews:
            embedding = model.encode(review).tolist()
            # index.upsert([{
            #     "id": str(uuid4()),
            #     "values": embedding,
            #     "metadata": {
            #         "skin_type": skin_type,
            #         "product_name": product_name,
            #         "review": review
            #     }
            # }])
        print("âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print("âŒ ìƒ˜í”Œ ì—…ë¡œë“œ ì‹¤íŒ¨:", e)


# âœ… ê¸°ì¡´ /recommendìš© ìŠ¤í‚¤ë§ˆ
class RecommendQuery(BaseModel):
    skin_type: str
    description: str

# âœ… ìƒˆë¡œìš´ /recommend/aiìš© ìŠ¤í‚¤ë§ˆ
class RecommendAIRequest(BaseModel):
    diagnosis: List[str]
    skin_type: str
    sensitivity: str


# âœ… ì„ë² ë”© ìƒì„±
def extract_embedding(text: str) -> list:
    return model.encode(text).tolist()

# âœ… Pinecone ê²€ìƒ‰ (ì„ì‹œ ë¹„í™œì„±í™”)
def search_pinecone(embedding: list, skin_type: str = None):
    # ì„ì‹œë¡œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
    return {
        "matches": [
            {
                "metadata": {
                    "product_name": "ë¼ìš´ë“œë© ìì‘ë‚˜ë¬´ í† ë„ˆ",
                    "review": "ì†ë³´ìŠµì´ ì˜ ë˜ê³  ê°ì§ˆ ë¶€ê°ì´ ëœí•´ìš”.",
                    "skin_type": skin_type or "ê±´ì„±"
                }
            },
            {
                "metadata": {
                    "product_name": "ì´ë‹ˆìŠ¤í”„ë¦¬ ë¸”ë£¨ë² ë¦¬ ë¦¬ë°¸ëŸ°ì‹± í† ë„ˆ", 
                    "review": "ëˆì ì„ ì—†ì´ ì‚°ëœ»í•´ì„œ ì—¬ë¦„ì— ì¢‹ì•„ìš”.",
                    "skin_type": skin_type or "ì§€ì„±"
                }
            }
        ]
    }

# âœ… GPT ì‘ë‹µ ìƒì„± (ì„ì‹œ ë¹„í™œì„±í™”)
def generate_recommendation(query, results):
    matches = results.get("matches", [])
    if not matches:
        return "ì¶”ì²œí•  ì œí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    items = [x.get("metadata", {}) for x in matches]
    
    # OpenAI API ì—†ì´ ê¸°ë³¸ ì¶”ì²œ ë©”ì‹œì§€ ë°˜í™˜
    recommendation = f"""
{query.get('skin_type', 'ì¼ë°˜')} í”¼ë¶€íƒ€ì…ì— ë§ëŠ” ì œí’ˆ ì¶”ì²œ:

"""
    for i, item in enumerate(items, 1):
        product_name = item.get("product_name", "ì œí’ˆëª… ì—†ìŒ")
        review = item.get("review", "ë¦¬ë·° ì—†ìŒ")
        recommendation += f"{i}. {product_name}\n   - {review}\n\n"
    
    recommendation += "â€» ê°œì¸ì˜ í”¼ë¶€ ìƒíƒœì— ë”°ë¼ íš¨ê³¼ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    return recommendation



# âœ… ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œ API
@app.post("/recommend")
def recommend_endpoint(query: RecommendQuery):
    embedding = extract_embedding(f"{query.skin_type} í”¼ë¶€, {query.description}")
    results = search_pinecone(embedding, skin_type=query.skin_type)
    message = generate_recommendation(query.model_dump(), results)
    return {"ì¶”ì²œ ë©˜íŠ¸": message}


# âœ… AI ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì¶”ì²œ API
@app.post("/recommend/ai")
def recommend_ai(data: RecommendAIRequest):
    query_text = generate_recommend_query(data.diagnosis, data.skin_type, data.sensitivity)
    embedding = extract_embedding(query_text)
    results = search_pinecone(embedding, skin_type=data.skin_type)
    message = generate_recommendation(data.model_dump(), results)
    return {"ì¶”ì²œ ë©˜íŠ¸": message}
