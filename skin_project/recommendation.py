from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from pinecone import Pinecone
from openai import OpenAI
from skin_project.recommend_utils import generate_recommend_query
import os
from uuid import uuid4
from typing import List  # âœ… ì¶”ê°€

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
env_path = os.path.join(os.path.dirname(__file__), ".env")
load_dotenv(dotenv_path=env_path)

openai_api_key = os.getenv("OPENAI_API_KEY")
pinecone_api_key = os.getenv("PINECONE_API_KEY")
pinecone_env = os.getenv("PINECONE_ENV")
pinecone_index_name = os.getenv("PINECONE_INDEX", "toner")

print("âœ… OPENAI_API_KEY =", openai_api_key[:10] + "..." if openai_api_key else None)
print("ğŸ” PINECONE_API_KEY =", pinecone_api_key[:10] + "..." if pinecone_api_key else None)
print("ğŸ” PINECONE_ENV =", pinecone_env)
print("ğŸ” PINECONE_INDEX =", pinecone_index_name)

if not openai_api_key:
    raise RuntimeError("âŒ OPENAI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
if not pinecone_api_key or not pinecone_env:
    raise RuntimeError("âŒ PINECONE_API_KEY ë˜ëŠ” PINECONE_ENVê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

client = OpenAI(api_key=openai_api_key)
pc = Pinecone(api_key=pinecone_api_key, environment=pinecone_env)

if pinecone_index_name not in pc.list_indexes().names():
    raise RuntimeError(f"'{pinecone_index_name}' ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

index = pc.Index(pinecone_index_name)
model = SentenceTransformer("jhgan/ko-sbert-nli")
app = FastAPI()

# âœ… ìƒ˜í”Œ í† ë„ˆ ë°ì´í„° ì—…ë¡œë“œ
@app.on_event("startup")
async def upload_sample_data():
    try:
        reviews = [
            ("ê±´ì„±", "ë¼ìš´ë“œë© ìì‘ë‚˜ë¬´ í† ë„ˆ", "ì†ë³´ìŠµì´ ì˜ ë˜ê³  ê°ì§ˆ ë¶€ê°ì´ ëœí•´ìš”."),
            ("ì§€ì„±", "ì´ë‹ˆìŠ¤í”„ë¦¬ ë¸”ë£¨ë² ë¦¬ ë¦¬ë°¸ëŸ°ì‹± í† ë„ˆ", "ëˆì ì„ ì—†ì´ ì‚°ëœ»í•´ì„œ ì—¬ë¦„ì— ì¢‹ì•„ìš”."),
            ("ë¯¼ê°ì„±", "ì•„ë²¤ëŠ í† ë„ˆ", "ìê·¹ ì—†ì´ ì§„ì •ë¼ì„œ í”¼ë¶€ ì§„ì •ìš©ìœ¼ë¡œ ë”±ì´ì—ìš”."),
        ]
        for skin_type, product_name, review in reviews:
            embedding = model.encode(review).tolist()
            index.upsert([{
                "id": str(uuid4()),
                "values": embedding,
                "metadata": {
                    "skin_type": skin_type,
                    "product_name": product_name,
                    "review": review
                }
            }])
        print("âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print("âŒ ìƒ˜í”Œ ì—…ë¡œë“œ ì‹¤íŒ¨:", e)


# âœ… ê¸°ì¡´ /recommendìš© ìŠ¤í‚¤ë§ˆ
class RecommendQuery(BaseModel):
    skin_type: str
    description: str

# âœ… ìƒˆë¡œìš´ /recommend/aiìš© ìŠ¤í‚¤ë§ˆ
class RecommendAIRequest(BaseModel):
    diagnosis: List[str]
    skin_type: str
    sensitivity: str


# âœ… ì„ë² ë”© ìƒì„±
def extract_embedding(text: str) -> list:
    return model.encode(text).tolist()

# âœ… Pinecone ê²€ìƒ‰
def search_pinecone(embedding: list, skin_type: str = None):
    return index.query(
        vector=embedding,
        top_k=3,
        include_metadata=True,
        filter={"skin_type": skin_type} if skin_type else {}
    )

# âœ… GPT ì‘ë‹µ ìƒì„±
def generate_recommendation(query, results):
    matches = results.get("matches", [])
    if not matches:
        return "ì¶”ì²œí•  ì œí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    items = [x.get("metadata", {}) for x in matches]
    
    prompt = f"""
ì•„ë˜ í”¼ë¶€ ìƒíƒœì— ë§ëŠ” ì œí’ˆì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.  
ê° ì œí’ˆì— ëŒ€í•´ ì œí’ˆëª…, ì£¼ìš” íš¨ê³¼, ì–´ë–¤ í”¼ë¶€ ìƒíƒœì— ì í•©í•œì§€ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.  

í”¼ë¶€ ì •ë³´:
- í”¼ë¶€íƒ€ì…: {query['skin_type']}
- ë¯¼ê°ë„: {query.get('sensitivity', '')}
- ì§„ë‹¨: {query.get('description', '') or query.get('diagnosis', '')}

ì¶”ì²œ ëŒ€ìƒ ì œí’ˆ:
"""
    for i, item in enumerate(items, 1):
        product_name = item.get("product_name", "ì œí’ˆëª… ì—†ìŒ")
        review = item.get("review", "ë¦¬ë·° ì—†ìŒ")
        prompt += f"{i}. {product_name} - {review}\n"

    prompt += "\në§íˆ¬ëŠ” ê°„ê²°í•˜ê³ , ì´ëª¨ì§€ ì—†ì´, ì •ë³´ ìœ„ì£¼ë¡œ ì¨ì£¼ì„¸ìš”. ì—­í• ê·¹ì´ë‚˜ ì ì¥ì²˜ëŸ¼ ë§í•˜ì§€ ë§ˆì„¸ìš”."

    try:
        chat = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return chat.choices[0].message.content
    except Exception as e:
        return f"âŒ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}"



# âœ… ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œ API
@app.post("/recommend")
def recommend_endpoint(query: RecommendQuery):
    embedding = extract_embedding(f"{query.skin_type} í”¼ë¶€, {query.description}")
    results = search_pinecone(embedding, skin_type=query.skin_type)
    message = generate_recommendation(query.model_dump(), results)
    return {"ì¶”ì²œ ë©˜íŠ¸": message}


# âœ… AI ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì¶”ì²œ API
@app.post("/recommend/ai")
def recommend_ai(data: RecommendAIRequest):
    query_text = generate_recommend_query(data.diagnosis, data.skin_type, data.sensitivity)
    embedding = extract_embedding(query_text)
    results = search_pinecone(embedding, skin_type=data.skin_type)
    message = generate_recommendation(data.model_dump(), results)
    return {"ì¶”ì²œ ë©˜íŠ¸": message}
